---
title: "Applied example"
author: "Rachael Caelie (Rocky) Aikens"
date: "12/2/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center", cache.lazy = F)
library(RACplots)
library(optmatch)
library(DOS2)
library(tidyverse)
library(ggpubr)
library(mice)
library(stratamatch)
library(knitr)

theme_set(theme_light())
```

```{r}
AC_plot2 <- function(data, title = "", shaded_class = 1){
  if(shaded_class == "none"){
    plt_data <- data %>%
    mutate(t = as.factor(abs(1-t)),
           a = 0.9) %>%
    dplyr::select(c(t, prog, prop, a))
  } else{
     plt_data <- data %>%
      mutate(t = as.factor(abs(1-t)),
             a = ifelse(t == shaded_class, 0.9, 1)) %>%
      dplyr::select(c(t, prog, prop, a)) 
  }
  
  plt <- ggplot(data = plt_data, aes( x = prop, y = prog, group = t, color = t)) + 
    geom_point(size = 1, aes(alpha = a)) +
    scale_color_brewer(palette="Set1") +
    ggtitle(title) +
    theme(legend.position = "none", aspect.ratio=1, plot.title = element_text(hjust = 0.5, size = 9))+
    ylab(expression(paste("Prognosis, ", Psi, "(x)", sep = ""))) +
    xlab(expression(paste("Propensity, ", phi, "(x)", sep = "")))
  
  return(plt)
}
```


# Set-up

We'd like to ask the question: Do patients have better outcomes when their identities match their own?  To do so, we use a dataset of 1155903 coronary artery bypass grafting (cabg) surgeries on Medicare patients from 1998 to 2016.  We compare 30 day mortality for patients whose identities are matched to their primary surgeons with those whose identities are not.

Provider race is not recorded in the dataset, so we focus on sex/gender. Unfortunately, patients are characterized only by "sex" and providers are characterized only by "gender," and the data dictionaries don't really clarify what is meant by this. The remainder of this analysis will treat patient sex and provider gender match as "treated" and mismatch as "untreated." 

## Data cleaning

The original dataset contained 1155903 surgeries.  58 patients had a missing date for their surgery.  247686 had a recorded date, but no recorded gender information for their provider.  One observation had sex recorded as unknown and was removed from the analysis.  Otherwise, no patients had any recorded sex besides male or female, and no providers had any gender codes other than male or female. 908159 surgeries were included.

```{r}
# Read in CABG df and dataDict
cabg_raw <- read_csv("../data/cabg_cohort_rocky_12_01_2020.csv")
cabg_dataDict <- read_csv("../data/cabg_cohort_rocky_dataDict_12_02_2020.csv")

# All Beneficiary IDs are distinct, so replacing BENE_ID with new ID column
cabg_df <- cabg_raw %>%
  select(- BENE_ID) %>%
  mutate(BENE_ID = 1:dim(.)[1]) %>%
  rename(PROVIDER_GENDER = `Provider Gender Code`) %>%
  filter(!is.na(surgdate), !is.na(PROVIDER_GENDER), BENE_SEX_CD != 0)
```

Most pre-treatment covariates are more than 20% missing.  Only ischemia, hyperlipidimia, and hypertension are less than 80% missing.  I recode admissions codes to be "Emergency", "Urgent", "Elective" or "Other", since codes besides emergency, urgent, or elective are quite rare in the dataset.

```{r}
# taking a look at what comorbidity information is present enough to keep
completeness <- summarize_all(cabg_df, function(x) mean(!is.na(x))) %>% slice(1) %>% as.numeric()
variance <- summarize_all(cabg_df, function(x) var(x, na.rm = T)) %>% slice(1) %>% as.numeric()

colstats <- tibble(value = colnames(cabg_df), completeness = completeness, variance = variance)

#colstats %>% 
#  filter(completeness > 0.8, 
#         !endsWith(value, "bfdschrg"),
#         !endsWith(value, "EVER_IND"),
#         !endsWith(value, "YEAREND_IND"))
```

```{r}
set.seed(123)

# Since most admissions are 123 (Emergency, Urgent, or Elective), 
# I recode admission codes 0456789 to 0 = "Other"
cabg_cleaned <- cabg_df %>%
  select(BENE_ID, BENE_MDCR_STUS_CD, BENE_RSDNC_SSA_STATE_CD, 
         BENE_RACE_CD, BENE_SEX_CD, BENE_AGE_CNT, ADMSN_DAY_CD,
         IP_ADMSN_TYPE_CD, BENE_DEATH_DT,
         cabg_only, cabg_primary, surgdate, indexSurgyear, hosp_vol_99_10, 
         hosp_mvol_99_10, prior_cabg, PROVIDER_GENDER,
         ISCHEMICHEART_EVER_bfadmin, HYPERL_EVER_bfadmin, HYPERT_EVER_bfadmin) %>%
  mutate(MORT_30_DAY = ifelse(is.na(BENE_DEATH_DT), FALSE,
                              BENE_DEATH_DT < surgdate + 30),
         PROVIDER_GENDER = ifelse(PROVIDER_GENDER == "M", 1, 2),
         SEX_GENDER_MATCH = PROVIDER_GENDER == BENE_SEX_CD,
         BENE_MALE = BENE_SEX_CD == 1) %>% # recode SEX to binary. 1,2 coding sometimes causes bugs
  mutate(IP_ADMSN_TYPE_CD = ifelse(IP_ADMSN_TYPE_CD == 0 | IP_ADMSN_TYPE_CD > 3,
         0, IP_ADMSN_TYPE_CD)) %>%
  select(-c(BENE_DEATH_DT, PROVIDER_GENDER, surgdate, BENE_SEX_CD)) %>%
  mutate_at(c("BENE_MDCR_STUS_CD", "BENE_RSDNC_SSA_STATE_CD",
              "BENE_RACE_CD", "ADMSN_DAY_CD", "IP_ADMSN_TYPE_CD"),
            as.factor)
```

# Analysis

## Pooled

First, I reserved 10% of the control data as a pilot set to train a prognostic model.  Then I trained a propensity score model on the entire dataset.  The plot below shows an assignment-control plot from the fitted propensity and prognostic scores.  In order to avoid overplotting, only a subsample of 400 observations is shown.

```{r include=FALSE}
set.seed(123)
split.full <- split_pilot_set(cabg_cleaned, treat = "SEX_GENDER_MATCH",
                           pilot_fraction = 0.1,
                           group_by_covariates = c("BENE_RSDNC_SSA_STATE_CD", "BENE_MALE"))

prog_model <- glm(MORT_30_DAY ~ BENE_MALE + BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg,
                  family = binomial(), data = split.full$pilot_set)
summary(prog_model)

prog_scores <- predict(prog_model, newdata = split.full$analysis_set)

prop_model <- glm(SEX_GENDER_MATCH ~ BENE_MALE + BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + ADMSN_DAY_CD + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg ,
                  family = binomial(), data = cabg_cleaned)

summary(prop_model)

prop_scores <- predict(prop_model, newdata = split.full$analysis_set)
```

```{r}
set.seed(124)
a_set.full <- split.full$analysis_set %>%
  mutate(prop = prop_scores,
         prog = prog_scores,
         t = SEX_GENDER_MATCH ) %>%
  sample_n(size = 400)

AC_plot2(a_set.full, shaded_class = "none")
```

Right away something is obviously amiss.  Female patients are much more likely to be mismatched with their primary surgeon than male patients (see table below). Because of this stark contrast in propensity for treatment between these two groups, I stratify by patient gender and make separate plots for each of them.  In order to do so, I split both the pilot and analysis sets by patient sex and I estimate new prognostic and propensity score models for each of the two groups. Note that there is a large imbalance in pilot set size between the two groups because male patients are almost all "treated" and female patients are almost all "control."  In fact, there are ~1300 male controls in the pilot set and ~30000 female controls in the pilot set.  This is a tough position to be in because that means a prognostic model fit on the whole pilot set will be much better fit to females, but if we split the pilot set and fit two sex-specific prognostic models, the male prognostic model will probably be much worse fit than the female prognostic model.

```{r}
cabg_cleaned %>% group_by(BENE_MALE,SEX_GENDER_MATCH) %>%
  summarise(n()) %>% kable()
```

Shown another way, here are the fraction of treated individuals bamong men and women:

```{r}
cabg_cleaned %>% group_by(BENE_MALE) %>% summarize(`Percent Treated` = mean(SEX_GENDER_MATCH)) %>%
  kable()
```


## Males

Here's an assignment control plot for males.  In this plot, both the prognostic and propensity score models were fit on males only.  The propensity score model is fit on all males, while the prognostic score model is fit on only the males in the pilot set.  Again, I'm downsampling the data to avoid overplotting.

```{r include=FALSE}
a.m <- split.full$analysis_set %>% filter(BENE_MALE == 1)
p.m <- split.full$pilot_set %>% filter(BENE_MALE == 1)
full.m <- cabg_cleaned %>% filter(BENE_MALE == 1)

prog_model.m <- glm(MORT_30_DAY ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg,
                  family = binomial(), data = p.m)
summary(prog_model.m)

prog_scores.m <- predict(prog_model.m, newdata = a.m)

prop_model.m <- glm(SEX_GENDER_MATCH ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + ADMSN_DAY_CD + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg,
                  family = binomial(), data = full.m)

summary(prop_model.m)

prop_scores.m <- predict(prop_model.m, newdata = a.m)
```

```{r, eval = F}
# builds lasso prognostic score model
# just fixes everything at zero.
x_p.m <- model.matrix(MORT_30_DAY ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + prior_cabg, p.m)

x_a.m <- model.matrix(MORT_30_DAY ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + prior_cabg, a.m) 

y_p.m <- p.m %>%
  select(MORT_30_DAY) %>%
  as.matrix()

cvprog <- cv.glmnet(x_p.m, y_p.m, family = "binomial")
prog_scores.m <- predict(cvprog, newx = x_a.m, s = "lambda.min") 

```


```{r}
a_set.m <- a.m %>%
  mutate(prop = prop_scores.m,
         prog = prog_scores.m,
         t = SEX_GENDER_MATCH ) %>%
  sample_n(size = 2000)

AC_plot2(a_set.m, shaded_class = 0)
```

Why the big striations in prognostic score?  Sometimes this is normal.  When there are categorical covariates that are highly predictive of the outcome under the control assignment or the treatment assignment, this is reflected by striae or subgroups in the assignment control plot.  Sometimes this is an important indication because it suggests a variable or variables that may be important candidates for exact matching or stratification. 

However, in this specific instance, it's more likely that the prognostic model is just overfit - attributing large weight to categorical covariates that may not actually be meaningful. Part of the problem is probably that the outcome (30 day mortality) is quite rare, meaning that the model is difficult to fit, even with over 1,000 examples. The table below shows the outcomes among men in the pilot set.  Since only 42 individuals in the pilot set had the outcome of interest, it is perhaps unsurprising that we have a hard time obtaining a clear picture of which variation is most important to the outcome.  We will see that the prognostic score fit on the female pilot set sample is much smoother -- probably because overfitting is less of a concern with such a large pilot set.

```{r}
p.m %>% group_by(MORT_30_DAY) %>% summarize(n()) %>% kable()
```


## Females

Here's the same plot for the female patients, with prognostic and propensity models fit only for female patients.

```{r, include=FALSE}
a.f <- split.full$analysis_set %>% filter(BENE_MALE == 0)
p.f <- split.full$pilot_set %>% filter(BENE_MALE == 0)
full.f <- cabg_cleaned %>% filter(BENE_MALE == 0)

prog_model.f <- glm(MORT_30_DAY ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg,
                  family = binomial(), data = p.f)
summary(prog_model.f)

prog_scores.f <- predict(prog_model.f, newdata = a.f)

prop_model.f <- glm(SEX_GENDER_MATCH ~ BENE_MDCR_STUS_CD + 
                    BENE_RACE_CD + BENE_AGE_CNT + ADMSN_DAY_CD + IP_ADMSN_TYPE_CD +
                    cabg_only + cabg_primary + indexSurgyear + hosp_vol_99_10 +
                    hosp_mvol_99_10 + prior_cabg,
                  family = binomial(), data = full.f)

summary(prop_model.f)

prop_scores.f <- predict(prop_model.f, newdata = a.f)
```

```{r}
a_set.f <- a.f %>%
  mutate(prop = prop_scores.f,
         prog = prog_scores.f,
         t = SEX_GENDER_MATCH ) %>%
  sample_n(size = 2000)

AC_plot2(a_set.f)
```

The plot for female patients looks a lot better. This is probably because there are many more female control observations in the pilot set on which to fit a prognostic model.  The table below shows the outcomes of female patients in the pilot set.  Notice that there are many more observations with the outcome, helping with model fitting.

```{r}
p.f %>% group_by(MORT_30_DAY) %>% summarize(n()) %>% kable()
```

